from ultralytics import YOLO
import torch

from logic.config_watcher import cfg
from logic.capture import capture
from logic.visual import visuals
from logic.frame_parser import frameParser
from logic.hotkeys_watcher import hotkeys_watcher
from logic.checks import run_checks
import supervision as sv
    
tracker = sv.ByteTrack() if not cfg.disable_tracker else None

@torch.inference_mode()
def perform_detection(model, image, tracker: sv.ByteTrack | None = None):
    kwargs = dict(
        source=image,
        imgsz=cfg.ai_model_image_size,
        conf=cfg.AI_conf,
        iou=0.50,
        device=cfg.AI_device,
        half=not "cpu" in cfg.AI_device,
        max_det=20,
        agnostic_nms=False,
        augment=False,
        vid_stride=False,
        visualize=False,
        verbose=False,
        show_boxes=False,
        show_labels=False,
        show_conf=False,
        save=False,
        show=False,
        stream=True
    )

    kwargs["cfg"] = "logic/tracker.yaml" if tracker else "logic/game.yaml"

    results = model.predict(**kwargs)

    if tracker:
        for res in results:
            det = sv.Detections.from_ultralytics(res)
            return tracker.update_with_detections(det)
    else:
        return next(results)

def init():
    run_checks()
    
    try:
        model = YOLO(f"models/{cfg.AI_model_name}", task="detect")
    except Exception as e:
        print("An error occurred when loading the AI model:\n", e)
        quit(0)
        
    while True:
        image = capture.get_new_frame()
        
        if image is not None:
            if cfg.circle_capture:
                image = capture.convert_to_circle(image)
                
            if cfg.show_window or cfg.show_overlay:
                visuals.queue.put(image)
                
            result = perform_detection(model, image, tracker)

            if hotkeys_watcher.app_pause == 0:
                frameParser.parse(result)

if __name__ == "__main__":
    init()
    
    from ultralytics import YOLO
import torch

from logic.config_watcher import cfg
from logic.capture import capture
from logic.visual import visuals
from logic.frame_parser import frameParser
from logic.hotkeys_watcher import hotkeys_watcher
from logic.checks import run_checks
import supervision as sv
    
byte_tracker = sv.ByteTrack()

@torch.inference_mode()
def perform_detection(model, image, tracker=None):
    if tracker is not None:
        results = model.predict(
            source=image,
            cfg="logic/tracker.yaml",
            imgsz=cfg.ai_model_image_size,
            stream=True,
            conf=cfg.AI_conf,
            iou=0.5,
            device=cfg.AI_device,
            half=False if "cpu" in cfg.AI_device else True,
            max_det=20,
            agnostic_nms=False,
            augment=False,
            vid_stride=False,
            visualize=False,
            verbose=False,
            show_boxes=False,
            show_labels=False,
            show_conf=False,
            save=False,
            show=False)
        
        for result in results:
            # Convert results to detections
            detections = sv.Detections.from_ultralytics(result)
            tracked_detections = byte_tracker.update_with_detections(detections)
            return tracked_detections
    else:
        result = next(model.predict(
            source=image,
            cfg="logic/game.yaml",
            imgsz=cfg.ai_model_image_size,
            stream=True,
            conf=cfg.AI_conf,
            iou=0.5,
            device=cfg.AI_device,
            half=False if "cpu" in cfg.AI_device else True,
            max_det=20,
            agnostic_nms=False,
            augment=False,
            vid_stride=False,
            visualize=False,
            verbose=False,
            show_boxes=False,
            show_labels=False,
            show_conf=False,
            save=False,
            show=False))
        
        return result

def init():
    run_checks()
    
    try:
        model = YOLO(f"models/{cfg.AI_model_name}", task="detect")
    except Exception as e:
        print("An error occurred when loading the AI model:\n", e)
        quit(0)
        
    while True:
        image = capture.get_new_frame()
        
        if image is not None:
            if cfg.circle_capture:
                image = capture.convert_to_circle(image)
            
            if cfg.show_window or cfg.show_overlay:
                visuals.queue.put(image)
                
            result = perform_detection(model, image, byte_tracker)

            if hotkeys_watcher.app_pause == 0:
                frameParser.parse(result)

if __name__ == "__main__":
    init()
    +@torch.inference_mode()
+def perform_detection(model, image, tracker=None):
+    if tracker is not None:
+        results = model.predict(
+            source=image,
+            cfg="logic/tracker.yaml",
+            imgsz=cfg.ai_model_image_size,
+            stream=True,
+            conf=cfg.AI_conf,
+            iou=0.5,
+            device=cfg.AI_device,
+            half=False if "cpu" in cfg.AI_device else True,
+            max_det=20,
+            agnostic_nms=False,
+            augment=False,
+            vid_stride=False,
+            visualize=False,
+            verbose=False,
+            show_boxes=False,
+            show_labels=False,
+            show_conf=False,
+            save=False,
+            show=False)
+        
+        for result in results:
+            # Convert results to detections
+            detections = sv.Detections.from_ultralytics(result)
+            tracked_detections = byte_tracker.update_with_detections(detections)
+            return tracked_detections
+    else:
+        result = next(model.predict(
+            source=image,
+            cfg="logic/game.yaml",
+            imgsz=cfg.ai_model_image_size,
+            stream=True,
+            conf=cfg.AI_conf,
+            iou=0.5,
+            device=cfg.AI_device,
+            half=False if "cpu" in cfg.AI_device else True,
+            max_det=20,
+            agnostic_nms=False,
+            augment=False,
+            vid_stride=False,
+            visualize=False,
+            verbose=False,
+            show_boxes=False,
+            show_labels=False,
+            show_conf=False,
+            save=False,
+            show=False))
+        
+        return result
+
+def init():
+    run_checks()
+    
+    try:
+        model = YOLO(f"models/{cfg.AI_model_name}", task="detect")
+    except Exception as e:
+        print("An error occurred when loading the AI model:\n", e)
+        quit(0)
+        
+    while True:
+        image = capture.get_new_frame()
+        
+        if image is not None:
+            if cfg.circle_capture:
+                image = capture.convert_to_circle(image)
+            
+            if cfg.show_window or cfg.show_overlay:
+                visuals.queue.put(image)
+                
+            result = perform_detection(model, image, byte_tracker)
+
+            if hotkeys_watcher.app_pause == 0:
+                frameParser.parse(result)
+
+if __name__ == "__main__":
+    init()
+    
+    from ultralytics import YOLO
+import torch
+
+from logic.config_watcher import cfg
+from logic.capture import capture
+from logic.visual import visuals
+from logic.frame_parser import frameParser
+from logic.hotkeys_watcher import hotkeys_watcher
+from logic.checks import run_checks
+import supervision as sv
+    
+byte_tracker = sv.ByteTrack()