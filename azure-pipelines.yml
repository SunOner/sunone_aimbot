# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
- main

pool:
  vmImage: ubuntu-latest

strategy:
  matrix:
    Python38:
      python.version: '3.8'
    Python39:
      python.version: '3.9'
    Python310:
      python.version: '3.10'
    Python311:
      python.version: '3.11'

steps:
- task: UsePythonVersion@0
  inputs:
    versionSpec: '$(python.version)'
  displayName: 'Use Python $(python.version)'

- script: |
    python -m pip install --upgrade pip
    pip install -r requirements.txt
  displayName: 'Install dependencies'

- script: |
    pip install pytest pytest-azurepipelines
    pytest
  displayName: 'pytest'
+@torch.inference_mode()
+def perform_detection(model, image, tracker=None):
+    if tracker is not None:
+        results = model.predict(
+            source=image,
+            cfg="logic/tracker.yaml",
+            imgsz=cfg.ai_model_image_size,
+            stream=True,
+            conf=cfg.AI_conf,
+            iou=0.5,
+            device=cfg.AI_device,
+            half=False if "cpu" in cfg.AI_device else True,
+            max_det=20,
+            agnostic_nms=False,
+            augment=False,
+            vid_stride=False,
+            visualize=False,
+            verbose=False,
+            show_boxes=False,
+            show_labels=False,
+            show_conf=False,
+            save=False,
+            show=False)
+        
+        for result in results:
+            # Convert results to detections
+            detections = sv.Detections.from_ultralytics(result)
+            tracked_detections = byte_tracker.update_with_detections(detections)
+            return tracked_detections
+    else:
+        result = next(model.predict(
+            source=image,
+            cfg="logic/game.yaml",
+            imgsz=cfg.ai_model_image_size,
+            stream=True,
+            conf=cfg.AI_conf,
+            iou=0.5,
+            device=cfg.AI_device,
+            half=False if "cpu" in cfg.AI_device else True,
+            max_det=20,
+            agnostic_nms=False,
+            augment=False,
+            vid_stride=False,
+            visualize=False,
+            verbose=False,
+            show_boxes=False,
+            show_labels=False,
+            show_conf=False,
+            save=False,
+            show=False))
+        
+        return result
+
+def init():
+    run_checks()
+    
+    try:
+        model = YOLO(f"models/{cfg.AI_model_name}", task="detect")
+    except Exception as e:
+        print("An error occurred when loading the AI model:\n", e)
+        quit(0)
+        
+    while True:
+        image = capture.get_new_frame()
+        
+        if image is not None:
+            if cfg.circle_capture:
+                image = capture.convert_to_circle(image)
+            
+            if cfg.show_window or cfg.show_overlay:
+                visuals.queue.put(image)
+                
+            result = perform_detection(model, image, byte_tracker)
+
+            if hotkeys_watcher.app_pause == 0:
+                frameParser.parse(result)
+
+if __name__ == "__main__":
+    init()
+    
+    from ultralytics import YOLO
+import torch
+
+from logic.config_watcher import cfg
+from logic.capture import capture
+from logic.visual import visuals
+from logic.frame_parser import frameParser
+from logic.hotkeys_watcher import hotkeys_watcher
+from logic.checks import run_checks
+import supervision as sv
+    
+byte_tracker = sv.ByteTrack()